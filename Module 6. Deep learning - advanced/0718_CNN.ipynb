{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터셋을 합축 해제한 디렉터리 경로\n",
    "original_dataset_dir = './fruits-fresh-and-rotten-for-classification/dataset'\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소규모 데이터셋을 저장할 디렉터리\n",
    "base_dir = './fruits-fresh-and-rotten-for-classification/dataset/CNN'\n",
    "if os.path.exists(base_dir): # 반복적인 실행을 위해 디렉터리를 삭제합니다.\n",
    "    shutil.rmtree(base_dir) # 이 코드는 책에 포함되어 있지 않습니다.\n",
    "os.mkdir(base_dir)\n",
    "# base_dir = './datasets/datasets'\n",
    "\n",
    "validation_freshapple_dir = os.path.join(validation_dir, 'freshapples')\n",
    "os.mkdir(validation_freshapple_dir)\n",
    "\n",
    "validation_freshbanana_dir = os.path.join(validation_dir, 'freshbanana')\n",
    "os.mkdir(validation_freshbanana_dir)\n",
    "\n",
    "validation_freshorange_dir = os.path.join(validation_dir, 'freshoranges')\n",
    "os.mkdir(validation_freshorange_dir)\n",
    "\n",
    "validation_rottenapple_dir = os.path.join(validation_dir, 'rottenapples')\n",
    "os.mkdir(validation_rottenapple_dir)\n",
    "\n",
    "validation_rottenbanana_dir = os.path.join(validation_dir, 'rottenbanana')\n",
    "os.mkdir(validation_rottenbanana_dir)\n",
    "\n",
    "validation_rottenorange_dir = os.path.join(validation_dir, 'rottenoranges')\n",
    "os.mkdir(validation_rottenorange_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train')\n",
    "\n",
    "train_freshapple_dir = os.path.join(train_dir, 'freshapples')\n",
    "\n",
    "train_freshbanana_dir = os.path.join(train_dir, 'freshbanana')\n",
    "\n",
    "train_freshorange_dir = os.path.join(train_dir, 'freshoranges')\n",
    "\n",
    "train_rottenapple_dir = os.path.join(train_dir, 'rottenapples')\n",
    "\n",
    "train_rottenbanana_dir = os.path.join(train_dir, 'rottenbanana')\n",
    "\n",
    "train_rottenorange_dir = os.path.join(train_dir, 'rottenoranges')\n",
    "\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "test_freshapple_dir = os.path.join(test_dir, 'freshapples')\n",
    "\n",
    "test_freshbanana_dir = os.path.join(test_dir, 'freshbanana')\n",
    "\n",
    "test_freshorange_dir = os.path.join(test_dir, 'freshoranges')\n",
    "\n",
    "test_rottenapple_dir = os.path.join(test_dir, 'rottenapples')\n",
    "\n",
    "test_rottenbanana_dir = os.path.join(test_dir, 'rottenbanana')\n",
    "\n",
    "test_rottenorange_dir = os.path.join(test_dir, 'rottenoranges')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import *\n",
    "# validation\n",
    "directory = 'C:/Users/Affinity/Documents/fruits-fresh-and-rotten-for-classification/dataset/train/'\n",
    "folders = os.listdir(directory)\n",
    "for folder in folders:\n",
    "    file_select = directory + folder + '/'\n",
    "    files = os.listdir(file_select)\n",
    "    random_select = sample(files, 380) # 100개의 파일명을 랜덤으로 추출\n",
    "    for i in random_select:\n",
    "        src = file_select + i\n",
    "        dst = os.path.join(validation_dir, folder) + '/'\n",
    "        shutil.move(src, dst)\n",
    "# 각 폴더에서 500개씩 뽑아서 validation으로 보냄 -> validation 총 3000개 사용\n",
    "# test 2698개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__\n",
    "import os, shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2,\n",
    "                            height_shift_range=0.2, shear_range=0.2,\n",
    "                            zoom_range=0.2, horizontal_flip=True,\n",
    "                            fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네트워크 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 모든 이미지를 1/255로 스케일을 조정합니다\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # 타깃 디렉터리\n",
    "        train_dir,\n",
    "        # 모든 이미지를 150 × 150 크기로 바꿉니다\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # binary_crossentropy 손실을 사용하기 때문에 이진 레이블이 필요합니다\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras2",
   "language": "python",
   "name": "keras2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
